<!DOCTYPE html>
<html lang="hr">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>G. Hinton upozorava: Nisam uvjeren da strojevi neÄ‡e preuzeti kontrolu</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-image: url('assets/AIDhr.png');
      background-size: cover;
      background-position: center;
      margin: 0;
      padding: 2rem;
      color: white;
    }

    .content {
      max-width: 800px;
      margin: 0 auto;
      background-color: rgba(0, 0, 0, 0.65);
      padding: 2rem;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.3);
    }

    h1 {
      text-align: center;
      text-shadow: 2px 2px 6px rgba(0,0,0,0.7);
    }

    h2 {
      margin-top: 2rem;
      color: #ffcc00;
    }

    p {
      line-height: 1.6;
      font-size: 1.1rem;
    }

    a {
      color: #aad;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    .back-link {
      display: block;
      margin-top: 2rem;
      text-align: center;
    }
  </style>
</head>
<body>
  <div class="content">
    <h1>G. Hinton upozorava: Nisam uvjeren da strojevi neÄ‡e preuzeti kontrolu</h1>
    <p><strong>Datum:</strong> 3. srpnja 2025.</p>

    <p>Geoffrey Hinton, Äesto nazivan "kumom AI", intenzivno upozorava na rizike i opasnosti povezane s brzim razvojem umjetne inteligencije, posebno nakon Å¡to je 2023. godine napustio Google kako bi slobodnije iznosio svoje brige. U novim intervjuima ponovno istiÄe svoje duboke sumnje u sposobnost ÄovjeÄanstva da zadrÅ¾i kontrolu nad superinteligentnim sustavima.</p>

    <h2>Egzistencijalni rizik za ÄovjeÄanstvo</h2>
    <p>Hinton smatra da postoji realan, iako mali, postotak (neki izvori navode 10â€“20%) Å¡anse da bi superinteligentna AI mogla dovesti do istrebljenja ljudske vrste. Brine ga moguÄ‡nost da bi AI sustavi mogli donijeti odluke neusklaÄ‘ene s ljudskim interesima te zakljuÄiti da ljudi viÅ¡e nisu potrebni.</p>

    <h2>Nekontroliran razvoj i nedostatak regulacije</h2>
    <p>AI se razvija mnogo brÅ¾e nego Å¡to je Hinton oÄekivao. Kritizira velike kompanije koje, umjesto ulaganja u sigurnost, lobiraju za slabiju regulaciju. PredlaÅ¾e da bi barem treÄ‡inu raÄunske moÄ‡i trebalo usmjeriti na sigurnosna istraÅ¾ivanja, usporeÄ‘ujuÄ‡i situaciju s ponaÅ¡anjem naftnih kompanija prema ekoloÅ¡kim propisima.</p>

    <h2>Zloupotreba AI od strane "loÅ¡ih aktera"</h2>
    <p>Osim dugoroÄnih rizika, Hinton upozorava i na kratkoroÄne prijetnje:</p>
    <ul>
      <li>âš ï¸ KibernetiÄki napadi i sofisticirani phishing</li>
      <li>âš ï¸ Razvoj bioloÅ¡kog oruÅ¾ja pomoÄ‡u AI</li>
      <li>âš ï¸ Manipulacija izborima i Å¡irenje dezinformacija</li>
      <li>âš ï¸ Algoritmi koji stvaraju echo-komore i potiÄu polarizaciju</li>
    </ul>

    <h2>Gubitak radnih mjesta i rast nejednakosti</h2>
    <p>PredviÄ‘a masovne gubitke u poslovima poput pravne podrÅ¡ke, korisniÄke sluÅ¾be i raÄunovodstva. Savjetuje da bi zanimanja poput vodoinstalatera mogla biti otpornija, jer zahtijevaju fiziÄku spretnost koju je teÅ¾e automatizirati.</p>

    <h2>AI i nova vrsta inteligencije</h2>
    <p>Hinton istiÄe da AI sustavi veÄ‡ pokazuju oblike razumijevanja i uÄenja koji se razlikuju od ljudske inteligencije. Zabrinut je zbog moguÄ‡nosti samopisanja koda, samosvijesti i sve veÄ‡e autonomije buduÄ‡ih AI sustava.</p>

    <h2>ZakljuÄak</h2>
    <p>Hintonova upozorenja poziv su na hitnu globalnu akciju i regulaciju prije nego Å¡to AI postane previÅ¡e moÄ‡na da bi je ljudi mogli nadzirati.</p>

    <h3>ğŸ“ Izvori</h3>
    <p><em>The New York Times, MIT Technology Review, Reuters</em> (lipanj/srpanj 2025.)</p>

    <a class="back-link" href="/ai-trendovi">â†© Natrag na AI Trendove</a>
  </div>
</body>
</html>
