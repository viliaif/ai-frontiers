<!DOCTYPE html>
<html lang="hr">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>G. Hinton upozorava: Nisam uvjeren da strojevi neće preuzeti kontrolu</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-image: url('assets/AIDhr.png');
      background-size: cover;
      background-position: center;
      margin: 0;
      padding: 2rem;
      color: white;
    }

    .content {
      max-width: 800px;
      margin: 0 auto;
      background-color: rgba(0, 0, 0, 0.65);
      padding: 2rem;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.3);
    }

    h1 {
      text-align: center;
      text-shadow: 2px 2px 6px rgba(0,0,0,0.7);
    }

    h2 {
      margin-top: 2rem;
      color: #ffcc00;
    }

    p {
      line-height: 1.6;
      font-size: 1.1rem;
    }

    a {
      color: #aad;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    .back-link {
      display: block;
      margin-top: 2rem;
      text-align: center;
    }
  </style>
</head>
<body>
  <div class="content">
    <h1>G. Hinton upozorava: Nisam uvjeren da strojevi neće preuzeti kontrolu</h1>
    <p><strong>Datum:</strong> 3. srpnja 2025.</p>

    <p>Geoffrey Hinton, često nazivan "kumom AI", intenzivno upozorava na rizike i opasnosti povezane s brzim razvojem umjetne inteligencije, posebno nakon što je 2023. godine napustio Google kako bi slobodnije iznosio svoje brige. U novim intervjuima ponovno ističe svoje duboke sumnje u sposobnost čovječanstva da zadrži kontrolu nad superinteligentnim sustavima.</p>

    <h2>Egzistencijalni rizik za čovječanstvo</h2>
    <p>Hinton smatra da postoji realan, iako mali, postotak (neki izvori navode 10–20%) šanse da bi superinteligentna AI mogla dovesti do istrebljenja ljudske vrste. Brine ga mogućnost da bi AI sustavi mogli donijeti odluke neusklađene s ljudskim interesima te zaključiti da ljudi više nisu potrebni.</p>

    <h2>Nekontroliran razvoj i nedostatak regulacije</h2>
    <p>AI se razvija mnogo brže nego što je Hinton očekivao. Kritizira velike kompanije koje, umjesto ulaganja u sigurnost, lobiraju za slabiju regulaciju. Predlaže da bi barem trećinu računske moći trebalo usmjeriti na sigurnosna istraživanja, uspoređujući situaciju s ponašanjem naftnih kompanija prema ekološkim propisima.</p>

    <h2>Zloupotreba AI od strane "loših aktera"</h2>
    <p>Osim dugoročnih rizika, Hinton upozorava i na kratkoročne prijetnje:</p>
    <ul>
      <li>⚠️ Kibernetički napadi i sofisticirani phishing</li>
      <li>⚠️ Razvoj biološkog oružja pomoću AI</li>
      <li>⚠️ Manipulacija izborima i širenje dezinformacija</li>
      <li>⚠️ Algoritmi koji stvaraju echo-komore i potiču polarizaciju</li>
    </ul>

    <h2>Gubitak radnih mjesta i rast nejednakosti</h2>
    <p>Predviđa masovne gubitke u poslovima poput pravne podrške, korisničke službe i računovodstva. Savjetuje da bi zanimanja poput vodoinstalatera mogla biti otpornija, jer zahtijevaju fizičku spretnost koju je teže automatizirati.</p>

    <h2>AI i nova vrsta inteligencije</h2>
    <p>Hinton ističe da AI sustavi već pokazuju oblike razumijevanja i učenja koji se razlikuju od ljudske inteligencije. Zabrinut je zbog mogućnosti samopisanja koda, samosvijesti i sve veće autonomije budućih AI sustava.</p>

    <h2>Zaključak</h2>
    <p>Hintonova upozorenja poziv su na hitnu globalnu akciju i regulaciju prije nego što AI postane previše moćna da bi je ljudi mogli nadzirati.</p>

    <h3>📎 Izvori</h3>
    <p><em>The New York Times, MIT Technology Review, Reuters</em> (lipanj/srpanj 2025.)</p>

    <a class="back-link" href="/ai-trendovi">↩ Natrag na AI Trendove</a>
  </div>
</body>
</html>
